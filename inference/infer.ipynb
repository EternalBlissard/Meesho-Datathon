{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08046f22-db0f-45bb-8aa5-18309a23a1e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:23.940808Z",
     "iopub.status.busy": "2024-10-14T11:28:23.940248Z",
     "iopub.status.idle": "2024-10-14T11:28:26.614016Z",
     "shell.execute_reply": "2024-10-14T11:28:26.613452Z",
     "shell.execute_reply.started": "2024-10-14T11:28:23.940788Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel\n",
    "from torchinfo import summary  # \n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3438730c-888d-4fd7-b57e-8ff63ab4f94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.616389Z",
     "iopub.status.busy": "2024-10-14T11:28:26.616065Z",
     "iopub.status.idle": "2024-10-14T11:28:26.620522Z",
     "shell.execute_reply": "2024-10-14T11:28:26.619968Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.616371Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\"\n",
    "def setAllSeeds(seed):\n",
    "  os.environ['MY_GLOBAL_SEED'] = str(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "setAllSeeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a86c36-a933-42bf-92c1-bd6cfbf0975b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.625620Z",
     "iopub.status.busy": "2024-10-14T11:28:26.625171Z",
     "iopub.status.idle": "2024-10-14T11:28:26.717777Z",
     "shell.execute_reply": "2024-10-14T11:28:26.717238Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.625599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Men Tshirts' 'Sarees' 'Kurtis' 'Women Tshirts' 'Women Tops & Tunics']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23280</th>\n",
       "      <td>23564</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23281</th>\n",
       "      <td>23565</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>23566</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23283</th>\n",
       "      <td>23567</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23284</th>\n",
       "      <td>23568</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category\n",
       "23280  23564  Women Tops & Tunics\n",
       "23281  23565  Women Tops & Tunics\n",
       "23282  23566  Women Tops & Tunics\n",
       "23283  23567  Women Tops & Tunics\n",
       "23284  23568  Women Tops & Tunics"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "categories=df[\"Category\"].unique()\n",
    "print(categories)\n",
    "category=categories[4]\n",
    "df = df[df[\"Category\"]==category]\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df = test_df[test_df[\"Category\"]==category]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df2da111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 'black', 1: 'navy blue', 2: 'red', 3: 'default', 4: 'maroon', 5: 'white', 6: 'green', 7: 'blue', 8: 'pink', 9: 'yellow', 10: 'peach', 11: 'multicolor'}, 1: {0: 'regular', 1: 'fitted', 2: 'boxy', 3: 'default'}, 2: {0: 'crop', 1: 'regular'}, 3: {0: 'high', 1: 'round neck', 2: 'stylised', 3: 'sweetheart neck', 4: 'v-neck', 5: 'square neck', 6: 'default'}, 4: {0: 'casual', 1: 'party'}, 5: {0: 'default', 1: 'printed', 2: 'solid'}, 6: {0: 'solid', 1: 'typography', 2: 'graphic', 3: 'default', 4: 'quirky', 5: 'floral'}, 7: {0: 'short sleeves', 1: 'sleeveless', 2: 'three-quarter sleeves', 3: 'long sleeves'}, 8: {0: 'regular sleeves', 1: 'default', 2: 'sleeveless', 3: 'puff sleeves'}, 9: {0: 'knitted', 1: 'default', 2: 'ruffles', 3: 'waist tie-ups', 4: 'tie-ups', 5: 'applique'}}\n",
      "{0: {'black': 0, 'navy blue': 1, 'red': 2, 'default': 3, 'maroon': 4, 'white': 5, 'green': 6, 'blue': 7, 'pink': 8, 'yellow': 9, 'peach': 10, 'multicolor': 11}, 1: {'regular': 0, 'fitted': 1, 'boxy': 2, 'default': 3}, 2: {'crop': 0, 'regular': 1}, 3: {'high': 0, 'round neck': 1, 'stylised': 2, 'sweetheart neck': 3, 'v-neck': 4, 'square neck': 5, 'default': 6}, 4: {'casual': 0, 'party': 1}, 5: {'default': 0, 'printed': 1, 'solid': 2}, 6: {'solid': 0, 'typography': 1, 'graphic': 2, 'default': 3, 'quirky': 4, 'floral': 5}, 7: {'short sleeves': 0, 'sleeveless': 1, 'three-quarter sleeves': 2, 'long sleeves': 3}, 8: {'regular sleeves': 0, 'default': 1, 'sleeveless': 2, 'puff sleeves': 3}, 9: {'knitted': 0, 'default': 1, 'ruffles': 2, 'waist tie-ups': 3, 'tie-ups': 4, 'applique': 5}}\n",
      "{0: 'attr_1', 1: 'attr_2', 2: 'attr_3', 3: 'attr_4', 4: 'attr_5', 5: 'attr_6', 6: 'attr_7', 7: 'attr_8', 8: 'attr_9', 9: 'attr_10'}\n"
     ]
    }
   ],
   "source": [
    "id2label={}\n",
    "label2id={}\n",
    "attrs={}\n",
    "total_attr=len(df.columns)\n",
    "for i in range(3,total_attr):\n",
    "    labels=df[df.columns[i]].dropna().unique()\n",
    "    id2label[i-3]={k:labels[k] for k in range(len(labels))}\n",
    "    label2id[i-3]={labels[k]:k for k in range(len(labels))}\n",
    "    attrs[i-3]=df.columns[i]\n",
    "print(id2label)\n",
    "print(label2id)\n",
    "print(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d71000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "model_name = f'vit/{category}/final'\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1113befc-d9c0-427e-98c8-467977f0f7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.751798Z",
     "iopub.status.busy": "2024-10-14T11:28:26.751660Z",
     "iopub.status.idle": "2024-10-14T11:28:26.756144Z",
     "shell.execute_reply": "2024-10-14T11:28:26.755669Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.751778Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomFashionManager(Dataset):\n",
    "    def __init__(self,csv_file, root_dir=\"./\",transforms =None):\n",
    "        self.fashionItems = csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fashionItems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,f\"{self.fashionItems.iloc[idx, 0]:06d}\"+'.jpg')\n",
    "        image = Image.open(img_name)\n",
    "        inputs=processor(image, return_tensors='pt')\n",
    "        \n",
    "\n",
    "        # if self.transforms:\n",
    "        #     sample = self.transforms(sample)\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "798bdc15-2101-4eb7-a52f-6748fd70d5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.756919Z",
     "iopub.status.busy": "2024-10-14T11:28:26.756780Z",
     "iopub.status.idle": "2024-10-14T11:28:27.051779Z",
     "shell.execute_reply": "2024-10-14T11:28:27.051275Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.756906Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fashion_data = CustomFashionManager(csv_file=df,root_dir='train_images')\n",
    "test_fashion_data = CustomFashionManager(csv_file=test_df,root_dir='test_images')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d3d845-6704-4cc0-acdd-a12ee3f1f8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:27.578464Z",
     "iopub.status.busy": "2024-10-14T11:28:27.578296Z",
     "iopub.status.idle": "2024-10-14T11:28:28.848764Z",
     "shell.execute_reply": "2024-10-14T11:28:28.848059Z",
     "shell.execute_reply.started": "2024-10-14T11:28:27.578419Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "from transformers import ViTConfig,ViTPreTrainedModel\n",
    "\n",
    "\n",
    "class CustomConfig(ViTConfig):\n",
    "    def __init__(self,num_classes_per_label:List[int]=[1],**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes_per_label = num_classes_per_label\n",
    "\n",
    "class MultiLabelMultiClassViT(ViTPreTrainedModel):\n",
    "    config_class=CustomConfig\n",
    "    def __init__(self, config: CustomConfig) -> None:\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.vit = ViTModel(config, add_pooling_layer=False)\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.Linear(config.hidden_size, num_classes) \n",
    "            for num_classes in config.num_classes_per_label\n",
    "        ])\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, pixel_values,labels=None):\n",
    "        outputs = self.vit(pixel_values).last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        logits = [classifier(outputs) for classifier in self.classifiers]\n",
    "        if labels is not None:\n",
    "            loss=0\n",
    "            for i in range(len(logits)):\n",
    "                target=labels[:,i]\n",
    "                loss += torch.nn.functional.cross_entropy(logits[i], target)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be5327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MultiLabelMultiClassViT.from_pretrained(model_name)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.cat([x['pixel_values'] for x in batch],dim=0),\n",
    "    }\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits = pred.predictions\n",
    "    labels=pred.label_ids\n",
    "    probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "    probs=probs.T\n",
    "    report=classification_report(labels.flatten(),probs.flatten(),output_dict=True)\n",
    "    return {'accuracy': report['accuracy'],\"macro avg f1\":report['macro avg']['f1-score']}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit/\"+category,\n",
    "  per_device_train_batch_size=96,\n",
    "  per_device_eval_batch_size=96,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  num_train_epochs=1,\n",
    "  fp16=True,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=1,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to=\"none\",\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_fashion_data,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3474278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5/73 00:06 < 01:42, 0.66 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_fashion_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:3946\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3943\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3945\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3946\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3949\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:4051\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4048\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4050\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 4051\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   4052\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   4053\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   4054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/data_loader.py:463\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/utils/operations.py:183\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 183\u001b[0m         {\n\u001b[1;32m    184\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking, skip_keys\u001b[38;5;241m=\u001b[39mskip_keys)\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    186\u001b[0m         }\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/utils/operations.py:184\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    183\u001b[0m         {\n\u001b[0;32m--> 184\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    186\u001b[0m         }\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/utils/operations.py:155\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    153\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "y_pred=trainer.predict(test_fashion_data)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f439fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 3 1 2 0]]\n",
      "[['navy blue', 'fitted', 'crop', 'high', 'casual', 'default', 'default', 'sleeveless', 'sleeveless', 'knitted']]\n",
      "id          0\n",
      "Category    0\n",
      "len         0\n",
      "attr_1      0\n",
      "attr_2      0\n",
      "attr_3      0\n",
      "attr_4      0\n",
      "attr_5      0\n",
      "attr_6      0\n",
      "attr_7      0\n",
      "attr_8      0\n",
      "attr_9      0\n",
      "attr_10     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "logits = y_pred.predictions\n",
    "probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "probs=probs.T\n",
    "print(probs)\n",
    "l=[]\n",
    "for i in range(len(probs)):\n",
    "    x=[]\n",
    "    for j in range(len(probs[i])):\n",
    "        x.append(id2label[j][probs[i][j]])\n",
    "    l.append(x)\n",
    "print(l)\n",
    "test_df['len']=len(l[0])\n",
    "for i in range(10):\n",
    "    x=[]\n",
    "    for j in range(len(l)):\n",
    "        if i<len(l[0]) and l[j][i]!=np.nan:\n",
    "            x.append(l[j][i])\n",
    "        else:\n",
    "            x.append(np.nan)\n",
    "    test_df[f\"attr_{i+1}\"]=x\n",
    "print(test_df.isna().sum())\n",
    "# test_df.to_csv(f\"preds/{category}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhcp4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
