{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08046f22-db0f-45bb-8aa5-18309a23a1e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:23.940808Z",
     "iopub.status.busy": "2024-10-14T11:28:23.940248Z",
     "iopub.status.idle": "2024-10-14T11:28:26.614016Z",
     "shell.execute_reply": "2024-10-14T11:28:26.613452Z",
     "shell.execute_reply.started": "2024-10-14T11:28:23.940788Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel\n",
    "from torchinfo import summary  # \n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import EfficientNetForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3438730c-888d-4fd7-b57e-8ff63ab4f94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.616389Z",
     "iopub.status.busy": "2024-10-14T11:28:26.616065Z",
     "iopub.status.idle": "2024-10-14T11:28:26.620522Z",
     "shell.execute_reply": "2024-10-14T11:28:26.619968Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.616371Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\"\n",
    "def setAllSeeds(seed):\n",
    "  os.environ['MY_GLOBAL_SEED'] = str(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "# setAllSeeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a86c36-a933-42bf-92c1-bd6cfbf0975b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.625620Z",
     "iopub.status.busy": "2024-10-14T11:28:26.625171Z",
     "iopub.status.idle": "2024-10-14T11:28:26.717777Z",
     "shell.execute_reply": "2024-10-14T11:28:26.717238Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.625599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Men Tshirts' 'Sarees' 'Kurtis' 'Women Tshirts' 'Women Tops & Tunics']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "categories=df[\"Category\"].unique()\n",
    "print(categories)\n",
    "category=categories[1]\n",
    "df = df[df[\"Category\"]==category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c43f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "Category        0\n",
       "len             0\n",
       "attr_1      10461\n",
       "attr_2        667\n",
       "attr_3       2485\n",
       "attr_4        450\n",
       "attr_5        697\n",
       "attr_6      13336\n",
       "attr_7       9450\n",
       "attr_8       1881\n",
       "attr_9       4043\n",
       "attr_10       528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae75c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_i=1\n",
    "removing_attri=[]\n",
    "df.iloc[:,3:2+attr_i]=np.nan\n",
    "df.iloc[:,3+attr_i:]=np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8232843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218fb75d-1b90-416b-9a41-288de39def1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.719372Z",
     "iopub.status.busy": "2024-10-14T11:28:26.719005Z",
     "iopub.status.idle": "2024-10-14T11:28:26.725099Z",
     "shell.execute_reply": "2024-10-14T11:28:26.724553Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.719356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['same as saree' 'solid' 'same as border' 'default']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "delCol = []\n",
    "idxCol = []\n",
    "trackNum = []\n",
    "weights=[]\n",
    "m=nn.Softmax(dim=1)\n",
    "l=[]\n",
    "for i in range(1,11):\n",
    "    uniName = df[\"attr_\"+str(i)].dropna().unique()\n",
    "    print(uniName)\n",
    "    if(len(uniName)==0):\n",
    "        delCol.append(\"attr_\"+str(i))\n",
    "    else:\n",
    "        idxCol.append(\"attr_\"+str(i))\n",
    "        l.append('attr_'+str(i))\n",
    "        trackNum.append(len(uniName))\n",
    "        class_weights=compute_class_weight(class_weight=\"balanced\",classes=uniName,y=df[\"attr_\"+str(i)].dropna())\n",
    "        weights.append(torch.tensor([1]*len(uniName),dtype=torch.float32).to(DEVICE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d305da-99e2-424a-b774-b1ffdbd56fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.732549Z",
     "iopub.status.busy": "2024-10-14T11:28:26.732338Z",
     "iopub.status.idle": "2024-10-14T11:28:26.736656Z",
     "shell.execute_reply": "2024-10-14T11:28:26.736114Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.732533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18346, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(delCol,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ce1ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "Category        0\n",
       "len             0\n",
       "attr_1      10461\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a251fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2da111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 'same as saree', 1: 'solid', 2: 'same as border', 3: 'default'}}\n",
      "{0: {'same as saree': 0, 'solid': 1, 'same as border': 2, 'default': 3}}\n",
      "{0: 'attr_1'}\n"
     ]
    }
   ],
   "source": [
    "id2label={}\n",
    "label2id={}\n",
    "attrs={}\n",
    "total_attr=len(df.columns)\n",
    "for i in range(3,total_attr):\n",
    "    labels=df[df.columns[i]].dropna().unique()\n",
    "    # print(df.columns[i],labels)\n",
    "    id2label[i-3]={k:labels[k] for k in range(len(labels))}\n",
    "    label2id[i-3]={labels[k]:k for k in range(len(labels))}\n",
    "    attrs[i-3]=df.columns[i]\n",
    "print(id2label)\n",
    "print(label2id)\n",
    "print(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f394a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>7432</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>7433</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>7434</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7435</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>7436</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Category  len  attr_1\n",
       "7267  7432   Sarees   10       0\n",
       "7268  7433   Sarees   10    -100\n",
       "7269  7434   Sarees   10    -100\n",
       "7270  7435   Sarees   10       0\n",
       "7271  7436   Sarees   10       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(example):\n",
    "    for i in attrs:\n",
    "        # print(example[attrs[i]],type(example[attrs[i]]),pd.isna(example[attrs[i]]))\n",
    "        if not pd.isna(example[attrs[i]]):\n",
    "            example[attrs[i]]=label2id[i][example[attrs[i]]]\n",
    "        else:\n",
    "            example[attrs[i]]=-100\n",
    "    return example\n",
    "df=df.apply(categorize,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1df7b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "Category    0\n",
       "len         0\n",
       "attr_1      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778a3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d886c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "332990dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum count across all categories is: 177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "min_count = train_df[f'attr_{attr_i}'].value_counts().min()\n",
    "print(f\"The minimum count across all categories is: {min_count}\")\n",
    "df_sampled = train_df.groupby(f'attr_{attr_i}').sample(n=min_count, random_state=42)\n",
    "train_df = df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "933021b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_1\n",
      "-100    177\n",
      " 0      177\n",
      " 1      177\n",
      " 2      177\n",
      " 3      177\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3100d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights[4]=torch.tensor([1,20],dtype=torch.float32).to(DEVICE)\n",
    "# weights[9]=torch.tensor([1,1,1,1,3,2],dtype=torch.float32).to(DEVICE)\n",
    "# weights[7]=torch.tensor([1,10],dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e10ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in l:\n",
    "#     print(i)\n",
    "#     for j in set(train_df[i].unique()):\n",
    "#         x=train_df[i][train_df[i]==j]\n",
    "#         if x.count()<300 and j!=-100:\n",
    "#             y=train_df[train_df[i]==j]\n",
    "#             y.iloc[:,3:]=-100\n",
    "#             y[i]=j\n",
    "#             print(y)\n",
    "#             train_df=pd.concat([train_df,y,y]).reset_index(drop=True)\n",
    "# for i in l:\n",
    "#     print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36416a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22095</th>\n",
       "      <td>22260</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>7773</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23614</th>\n",
       "      <td>23779</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>15001</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23116</th>\n",
       "      <td>23281</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category  len  attr_1\n",
       "22095  22260   Sarees   10    -100\n",
       "7608    7773   Sarees   10    -100\n",
       "23614  23779   Sarees   10    -100\n",
       "14836  15001   Sarees   10    -100\n",
       "23116  23281   Sarees   10    -100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80a27462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_1\n",
      "-100    177\n",
      " 0      177\n",
      " 1      177\n",
      " 2      177\n",
      " 3      177\n",
      "Name: count, dtype: int64\n",
      "attr_1\n",
      "-100    1046\n",
      " 0       539\n",
      " 2       155\n",
      " 3        84\n",
      " 1        11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[f'attr_{attr_i}'].value_counts())\n",
    "print(val_df[f'attr_{attr_i}'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfedae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "# model_name = 'google/vit-base-patch16-224'\n",
    "# model_name=f\"vit5/{category}/final\"\n",
    "model_name = 'google/efficientnet-b0'\n",
    "# model_name = 'vit6/'+category+'/final'\n",
    "# model_name=\"google/vit-large-patch16-224\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1113befc-d9c0-427e-98c8-467977f0f7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.751798Z",
     "iopub.status.busy": "2024-10-14T11:28:26.751660Z",
     "iopub.status.idle": "2024-10-14T11:28:26.756144Z",
     "shell.execute_reply": "2024-10-14T11:28:26.755669Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.751778Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomFashionManager(Dataset):\n",
    "    def __init__(self,csv_file, root_dir=\"./\",transforms =None):\n",
    "        self.fashionItems = csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fashionItems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,f\"{self.fashionItems.iloc[idx, 0]:06d}\"+'.jpg')\n",
    "        image = Image.open(img_name)\n",
    "        attributes = self.fashionItems.iloc[idx, 3:]\n",
    "        attributes = np.array(attributes)\n",
    "        attributes = attributes.astype('float')\n",
    "        \n",
    "        inputs=processor(image, return_tensors='pt')\n",
    "        inputs['labels']=torch.tensor(attributes, dtype=torch.long)\n",
    "        # if self.transforms:\n",
    "        #     inputs['pixel_values'] = self.transforms(inputs['pixel_values'])\n",
    "        \n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798bdc15-2101-4eb7-a52f-6748fd70d5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.756919Z",
     "iopub.status.busy": "2024-10-14T11:28:26.756780Z",
     "iopub.status.idle": "2024-10-14T11:28:27.051779Z",
     "shell.execute_reply": "2024-10-14T11:28:27.051275Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.756906Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transformations=transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.GaussianBlur(kernel_size=(9, 9), sigma=(0.1, 2.0)),\n",
    "])\n",
    "transformations=None\n",
    "train_fashion_data = CustomFashionManager(csv_file=train_df,\n",
    "                                    root_dir='train_images')\n",
    "val_fashion_data = CustomFashionManager(csv_file=val_df,\n",
    "                                    root_dir='train_images')\n",
    "test_fashion_data = CustomFashionManager(csv_file=df,root_dir='train_images')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d3d845-6704-4cc0-acdd-a12ee3f1f8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:27.578464Z",
     "iopub.status.busy": "2024-10-14T11:28:27.578296Z",
     "iopub.status.idle": "2024-10-14T11:28:28.848764Z",
     "shell.execute_reply": "2024-10-14T11:28:28.848059Z",
     "shell.execute_reply.started": "2024-10-14T11:28:27.578419Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "from transformers import (\n",
    "    ViTConfig,ViTPreTrainedModel,EfficientNetConfig,EfficientNetPreTrainedModel,\n",
    "    EfficientNetModel)\n",
    "\n",
    "\n",
    "class CustomConfig(EfficientNetConfig):\n",
    "    def __init__(self,num_classes_per_label:List[int]=[1],**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes_per_label = num_classes_per_label\n",
    "        # self.attn_implementation=\"sdpa\"\n",
    "        # self.hidden_size_2 = 382\n",
    "        # self.attention_probs_dropout_prob=0.1\n",
    "        # self.hidden_dropout_prob=0.1\n",
    "\n",
    "            \n",
    "class MultiLabelMultiClassViT(EfficientNetPreTrainedModel):\n",
    "    config_class=CustomConfig\n",
    "    def __init__(self, config: CustomConfig) -> None:\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.efficientnet = EfficientNetModel(config)\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Dropout(0.2),\n",
    "            # nn.Linear(config.hidden_size, 32),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(config.hidden_dim, num_classes))\n",
    "            # nn.Linear(49, num_classes)) \n",
    "            for num_classes in config.num_classes_per_label\n",
    "        ])\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, pixel_values,labels=None):\n",
    "        # outputs = self.efficientnet(pixel_values).last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        # outputs = outputs.reshape(outputs.shape[0],-1)\n",
    "        outputs=self.efficientnet(pixel_values).pooler_output\n",
    "        logits = [classifier(outputs) for classifier in self.classifiers]\n",
    "        if labels is not None:\n",
    "            loss=0\n",
    "            # loss_weights=np.array([1,1,1,1,1,1,1,5])\n",
    "            # loss_weights=loss_weights/loss_weights.sum()\n",
    "            for i in range(len(logits)):\n",
    "                target=labels[:,i]\n",
    "                loss += torch.nn.functional.cross_entropy(logits[i], target,ignore_index=-100)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "    \n",
    "# Example usage\n",
    "num_labels = len(trackNum)  # For example, 5 different labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "871286a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MultiLabelMultiClassViT were not initialized from the model checkpoint at google/efficientnet-b0 and are newly initialized: ['classifiers.0.1.bias', 'classifiers.0.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "MultiLabelMultiClassViT                                           --\n",
      "├─EfficientNetModel: 1-1                                          --\n",
      "│    └─EfficientNetEmbeddings: 2-1                                --\n",
      "│    │    └─ZeroPad2d: 3-1                                        --\n",
      "│    │    └─Conv2d: 3-2                                           864\n",
      "│    │    └─BatchNorm2d: 3-3                                      64\n",
      "│    │    └─SiLU: 3-4                                             --\n",
      "│    └─EfficientNetEncoder: 2-2                                   --\n",
      "│    │    └─ModuleList: 3-5                                       3,594,460\n",
      "│    │    └─Conv2d: 3-6                                           409,600\n",
      "│    │    └─BatchNorm2d: 3-7                                      2,560\n",
      "│    │    └─SiLU: 3-8                                             --\n",
      "│    └─AvgPool2d: 2-3                                             --\n",
      "├─ModuleList: 1-2                                                 --\n",
      "│    └─Sequential: 2-4                                            --\n",
      "│    │    └─Dropout: 3-9                                          --\n",
      "│    │    └─Linear: 3-10                                          5,124\n",
      "==========================================================================================\n",
      "Total params: 4,012,672\n",
      "Trainable params: 4,012,672\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "config=EfficientNetConfig.from_pretrained(model_name)\n",
    "config=CustomConfig(num_classes_per_label=trackNum,**config.to_dict())\n",
    "model = MultiLabelMultiClassViT.from_pretrained(model_name, config=config)\n",
    "\n",
    "# model=MultiLabelMultiClassViT.from_pretrained(model_name)\n",
    "# for param in model.vit.parameters():\n",
    "#     param.requires_grad = False\n",
    "# model.vit.pooler.parameters().__next__().requires_grad=True\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9be5327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "batch_size = 32\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.cat([x['pixel_values'] for x in batch],dim=0),\n",
    "        'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits = pred.predictions\n",
    "    labels=pred.label_ids\n",
    "    probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "    probs=probs.T\n",
    "    f1s=[]\n",
    "    for i in range(labels.shape[1]):\n",
    "        non_padding_indices = [j for j, label in enumerate(labels[:,i]) if label != -100]\n",
    "        labels_ = [labels[j,i] for j in non_padding_indices]\n",
    "        probs_ = [probs[j,i] for j in non_padding_indices]\n",
    "        micro=f1_score(labels_,probs_,average='micro')\n",
    "        macro=f1_score(labels_,probs_,average='macro')\n",
    "        print(f\"attr_{i} f1 score: {macro}\")\n",
    "        # print(classification_report(labels_,probs_))\n",
    "        score=2*(micro*macro)/(micro+macro)\n",
    "        f1s.append(score)\n",
    "    print()\n",
    "    print()\n",
    "    return {'score': sum(f1s)/len(f1s)}\n",
    "\n",
    "\n",
    "    # logits = pred.predictions\n",
    "    # labels=pred.label_ids\n",
    "    # probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "    # probs=probs.T\n",
    "    # labels=labels.flatten()\n",
    "    # probs=probs.flatten()\n",
    "    # non_padding_indices = [i for i, label in enumerate(labels) if label != -100]\n",
    "    # labels = [labels[i] for i in non_padding_indices]\n",
    "    # probs = [probs[i] for i in non_padding_indices]\n",
    "    # print(classification_report(labels,probs))\n",
    "    # report=classification_report(labels,probs,output_dict=True)\n",
    "    # return {'accuracy': report['accuracy'],\"macro avg f1\":report['macro avg']['f1-score']}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit6/\"+category,\n",
    "  per_device_train_batch_size=128,\n",
    "  per_device_eval_batch_size=128,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  logging_strategy=\"epoch\",\n",
    "  num_train_epochs=1,\n",
    "  bf16=True,\n",
    "  learning_rate=2e-4,\n",
    "#   dataloader_num_workers=20,lr\n",
    "  save_total_limit=1,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='wandb',\n",
    "  load_best_model_at_end=True,\n",
    "  metric_for_best_model=\"score\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_fashion_data,\n",
    "    eval_dataset=val_fashion_data,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dccb554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-16 15:10:28,840] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aseems/anaconda3/envs/mhcp4/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaran21258\u001b[0m (\u001b[33mkaran912\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aseems/ml/mchl/wandb/run-20241116_151032-m5rr857x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karan912/huggingface/runs/m5rr857x' target=\"_blank\">./vit6/Sarees</a></strong> to <a href='https://wandb.ai/karan912/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karan912/huggingface' target=\"_blank\">https://wandb.ai/karan912/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karan912/huggingface/runs/m5rr857x' target=\"_blank\">https://wandb.ai/karan912/huggingface/runs/m5rr857x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.205500</td>\n",
       "      <td>1.213278</td>\n",
       "      <td>0.458246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_0 f1 score: 0.41303227187448976\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_model() got an unexpected keyword argument 'safe_serialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./vit6/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcategory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/final\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_model() got an unexpected keyword argument 'safe_serialization'"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(f\"./vit6/{category}/final\",safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3474278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/144 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_0 f1 score: 0.5430645408423548\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8007969856262207,\n",
       " 'eval_score': 0.5964635895277907,\n",
       " 'eval_runtime': 89.996,\n",
       " 'eval_samples_per_second': 203.853,\n",
       " 'eval_steps_per_second': 1.6,\n",
       " 'epoch': 40.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_fashion_data)\n",
    "#1-54(imbalance),2-65,3-85,5-56,6-70,7-52(imbalance),8-51(imbalance),9-60(imbalance),10-49(imbalance)\n",
    "#4-30,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhcp4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
