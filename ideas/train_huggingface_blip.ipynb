{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08046f22-db0f-45bb-8aa5-18309a23a1e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:23.940808Z",
     "iopub.status.busy": "2024-10-14T11:28:23.940248Z",
     "iopub.status.idle": "2024-10-14T11:28:26.614016Z",
     "shell.execute_reply": "2024-10-14T11:28:26.613452Z",
     "shell.execute_reply.started": "2024-10-14T11:28:23.940788Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel\n",
    "from torchinfo import summary  # \n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3438730c-888d-4fd7-b57e-8ff63ab4f94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.616389Z",
     "iopub.status.busy": "2024-10-14T11:28:26.616065Z",
     "iopub.status.idle": "2024-10-14T11:28:26.620522Z",
     "shell.execute_reply": "2024-10-14T11:28:26.619968Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.616371Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\"\n",
    "def setAllSeeds(seed):\n",
    "  os.environ['MY_GLOBAL_SEED'] = str(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "# setAllSeeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a86c36-a933-42bf-92c1-bd6cfbf0975b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.625620Z",
     "iopub.status.busy": "2024-10-14T11:28:26.625171Z",
     "iopub.status.idle": "2024-10-14T11:28:26.717777Z",
     "shell.execute_reply": "2024-10-14T11:28:26.717238Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.625599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Men Tshirts' 'Sarees' 'Kurtis' 'Women Tshirts' 'Women Tops & Tunics']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "categories=df[\"Category\"].unique()\n",
    "print(categories)\n",
    "category=categories[1]\n",
    "df = df[df[\"Category\"]==category]\n",
    "df=df.iloc[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c43f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "Category      0\n",
       "len           0\n",
       "attr_1      274\n",
       "attr_2       20\n",
       "attr_3       66\n",
       "attr_4       15\n",
       "attr_5       16\n",
       "attr_6      353\n",
       "attr_7      255\n",
       "attr_8       49\n",
       "attr_9      119\n",
       "attr_10      17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae75c4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id Category  len         attr_1 attr_2 attr_3 attr_4 attr_5 attr_6  \\\n",
      "7267  7432   Sarees   10  same as saree    NaN    NaN    NaN    NaN    NaN   \n",
      "7268  7433   Sarees   10            NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "7269  7434   Sarees   10            NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "7270  7435   Sarees   10  same as saree    NaN    NaN    NaN    NaN    NaN   \n",
      "7271  7436   Sarees   10          solid    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "     attr_7 attr_8 attr_9 attr_10  \n",
      "7267    NaN    NaN    NaN     NaN  \n",
      "7268    NaN    NaN    NaN     NaN  \n",
      "7269    NaN    NaN    NaN     NaN  \n",
      "7270    NaN    NaN    NaN     NaN  \n",
      "7271    NaN    NaN    NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "df.iloc[:,3:2+i]=np.nan\n",
    "df.iloc[:,3+i:]=np.nan\n",
    "# df.iloc[:,[5,6]]=np.nan\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8232843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218fb75d-1b90-416b-9a41-288de39def1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.719372Z",
     "iopub.status.busy": "2024-10-14T11:28:26.719005Z",
     "iopub.status.idle": "2024-10-14T11:28:26.725099Z",
     "shell.execute_reply": "2024-10-14T11:28:26.724553Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.719356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['same as saree' 'solid' 'same as border' 'default']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "delCol = []\n",
    "idxCol = []\n",
    "trackNum = []\n",
    "weights=[]\n",
    "m=nn.Softmax(dim=1)\n",
    "l=[]\n",
    "for i in range(1,11):\n",
    "    uniName = df[\"attr_\"+str(i)].dropna().unique()\n",
    "    print(uniName)\n",
    "    if(len(uniName)==0):\n",
    "        delCol.append(\"attr_\"+str(i))\n",
    "    else:\n",
    "        idxCol.append(\"attr_\"+str(i))\n",
    "        l.append('attr_'+str(i))\n",
    "        trackNum.append(len(uniName))\n",
    "        class_weights=compute_class_weight(class_weight=\"balanced\",classes=uniName,y=df[\"attr_\"+str(i)].dropna())\n",
    "        weights.append(torch.tensor([1]*len(uniName),dtype=torch.float32).to(DEVICE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d305da-99e2-424a-b774-b1ffdbd56fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.732549Z",
     "iopub.status.busy": "2024-10-14T11:28:26.732338Z",
     "iopub.status.idle": "2024-10-14T11:28:26.736656Z",
     "shell.execute_reply": "2024-10-14T11:28:26.736114Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.732533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(delCol,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ce1ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "Category      0\n",
       "len           0\n",
       "attr_1      274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a251fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2da111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 'same as saree', 1: 'solid', 2: 'same as border', 3: 'default'}}\n",
      "{0: {'same as saree': 0, 'solid': 1, 'same as border': 2, 'default': 3}}\n",
      "{0: 'attr_1'}\n"
     ]
    }
   ],
   "source": [
    "id2label={}\n",
    "label2id={}\n",
    "attrs={}\n",
    "total_attr=len(df.columns)\n",
    "for i in range(3,total_attr):\n",
    "    labels=df[df.columns[i]].dropna().unique()\n",
    "    # print(df.columns[i],labels)\n",
    "    id2label[i-3]={k:labels[k] for k in range(len(labels))}\n",
    "    label2id[i-3]={labels[k]:k for k in range(len(labels))}\n",
    "    attrs[i-3]=df.columns[i]\n",
    "print(id2label)\n",
    "print(label2id)\n",
    "print(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f394a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>7432</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>7433</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>7434</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7435</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>7436</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Category  len attr_1\n",
       "7267  7432   Sarees   10      0\n",
       "7268  7433   Sarees   10       \n",
       "7269  7434   Sarees   10       \n",
       "7270  7435   Sarees   10      0\n",
       "7271  7436   Sarees   10      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(example):\n",
    "    for i in attrs:\n",
    "        # print(example[attrs[i]],type(example[attrs[i]]),pd.isna(example[attrs[i]]))\n",
    "        if not pd.isna(example[attrs[i]]):\n",
    "            example[attrs[i]]=label2id[i][example[attrs[i]]]\n",
    "        else:\n",
    "            example[attrs[i]]=''\n",
    "    return example\n",
    "df=df.apply(categorize,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1df7b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "Category    0\n",
       "len         0\n",
       "attr_1      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "332990dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df=train_df.head(10)\n",
    "# val_df,test_df=train_test_split(val_df,test_size=0.33)\n",
    "# train_df=df\n",
    "# val_df=train_df\n",
    "# test_df=train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933021b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_1\n",
      "     220\n",
      "0    112\n",
      "2     37\n",
      "3     29\n",
      "1      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e10ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in l:\n",
    "#     print(i)\n",
    "#     for j in set(train_df[i].unique()):\n",
    "#         x=train_df[i][train_df[i]==j]\n",
    "#         if x.count()<300 and j!=-100:\n",
    "#             y=train_df[train_df[i]==j]\n",
    "#             y.iloc[:,3:]=-100\n",
    "#             y[i]=j\n",
    "#             print(y)\n",
    "#             train_df=pd.concat([train_df,y,y]).reset_index(drop=True)\n",
    "# for i in l:\n",
    "#     print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36416a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>7681</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7700</th>\n",
       "      <td>7865</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>7451</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>7754</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>7764</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Category  len attr_1\n",
       "7516  7681   Sarees   10       \n",
       "7700  7865   Sarees   10      0\n",
       "7286  7451   Sarees   10      0\n",
       "7589  7754   Sarees   10       \n",
       "7599  7764   Sarees   10      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfedae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor,BlipProcessor,BlipForQuestionAnswering\n",
    "# model_name = 'google/vit-base-patch16-224'\n",
    "model_name=\"Salesforce/blip-vqa-base\"\n",
    "processor = BlipProcessor.from_pretrained(model_name)\n",
    "model = BlipForQuestionAnswering.from_pretrained(model_name).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1113befc-d9c0-427e-98c8-467977f0f7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.751798Z",
     "iopub.status.busy": "2024-10-14T11:28:26.751660Z",
     "iopub.status.idle": "2024-10-14T11:28:26.756144Z",
     "shell.execute_reply": "2024-10-14T11:28:26.755669Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.751778Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomFashionManager(Dataset):\n",
    "    def __init__(self,csv_file, root_dir=\"./\",transforms =None):\n",
    "        self.fashionItems = csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "        self.category_list=pd.read_csv(\"categories.csv\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fashionItems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,f\"{self.fashionItems.iloc[idx, 0]:06d}\"+'.jpg')\n",
    "        image = Image.open(img_name)\n",
    "        # prompt=self.category_list[self.category_list[\"Category\"]==self.fashionItems.iloc[idx, 1]].values()\n",
    "        prompt=\"blouse_pattern\"\n",
    "        \n",
    "        attributes = self.fashionItems.iloc[idx, 3]\n",
    "        # attributes = np.array(attributes)\n",
    "        # attributes = attributes.astype('float')\n",
    "        # print(' '.join(attributes))\n",
    "        inputs = processor(images=image, text=prompt, return_tensors=\"pt\",padding=\"max_length\",truncation=True)\n",
    "        labels = processor(text=str(attributes),padding='max_length',max_length=10,return_tensors=\"pt\").input_ids\n",
    "\n",
    "        inputs[\"labels\"] = labels\n",
    "        # inputs['labels']=torch.tensor(attributes, dtype=torch.long)\n",
    "        if self.transforms:\n",
    "            inputs['pixel_values'] = self.transforms(inputs['pixel_values'])\n",
    "            \n",
    "        for k,v in inputs.items():  inputs[k] = v.squeeze()\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798bdc15-2101-4eb7-a52f-6748fd70d5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.756919Z",
     "iopub.status.busy": "2024-10-14T11:28:26.756780Z",
     "iopub.status.idle": "2024-10-14T11:28:27.051779Z",
     "shell.execute_reply": "2024-10-14T11:28:27.051275Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.756906Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transformations=transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.GaussianBlur(kernel_size=(9, 9), sigma=(0.1, 2.0)),\n",
    "])\n",
    "transformations=None\n",
    "train_fashion_data = CustomFashionManager(csv_file=train_df,\n",
    "                                    root_dir='train_images')\n",
    "val_fashion_data = CustomFashionManager(csv_file=val_df,\n",
    "                                    root_dir='train_images')\n",
    "# test_fashion_data = CustomFashionManager(csv_file=test_df,root_dir='train_images')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be5327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "batch_size = 32\n",
    "# def collate_fn(batch):\n",
    "    # return {\n",
    "    #     'input_ids': torch.cat([x['input_ids'] for x in batch],dim=0),\n",
    "    #     'attention_mask': torch.cat([x['attention_mask'] for x in batch],dim=0),\n",
    "    #     'pixel_values': torch.cat([x['pixel_values'] for x in batch],dim=0),\n",
    "    #     'labels': torch.cat([x['labels'] for x in batch],dim=0)\n",
    "    # }\n",
    "\n",
    "def compute_metrics(probs,labels):\n",
    "    # probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "    # probs=probs.T\n",
    "    f1s=[]\n",
    "    # for i in range(len(labels)):\n",
    "    non_padding_indices = [j for j, label in enumerate(labels) if (label!= '' or label!=' ')]\n",
    "    labels_ = [labels[j] for j in non_padding_indices]\n",
    "    probs_ = [probs[j] for j in non_padding_indices]\n",
    "    print(labels_)\n",
    "    micro=f1_score(labels_,probs_,average='micro')\n",
    "    macro=f1_score(labels_,probs_,average='macro')\n",
    "    # print(f\"attr_{i} f1 score: {macro}\")\n",
    "    print(classification_report(labels_,probs_))\n",
    "    score=2*(micro*macro)/(micro+macro)\n",
    "    f1s.append(score)\n",
    "    print()\n",
    "    print()\n",
    "    return {'score': sum(f1s)/len(f1s)}\n",
    "\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, model, tokenizer, eval_dataloader,**kwargs):\n",
    "        # print(\"Evaluation done\")\n",
    "        model.config.use_cache = True\n",
    "        val_loader=DataLoader(val_fashion_data,batch_size=1)\n",
    "        preds=[]\n",
    "        labels=[]\n",
    "        for batch in tqdm(val_loader,total=len(val_loader)):\n",
    "            input_ids=batch['input_ids'].to(DEVICE)\n",
    "            pixel_values=batch['pixel_values'].to(DEVICE)\n",
    "            attention_mask=batch['attention_mask'].to(DEVICE)\n",
    "            outputs=model.generate(input_ids=input_ids,pixel_values=pixel_values,attention_mask=attention_mask)\n",
    "            text = tokenizer.batch_decode(outputs,skip_special_tokens=True)\n",
    "            label=tokenizer.batch_decode(batch['labels'],skip_special_tokens=True)\n",
    "            preds.extend(text)\n",
    "            labels.extend(label)\n",
    "        print(compute_metrics(preds,labels))\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./blip/\"+category,\n",
    "  per_device_train_batch_size=10,\n",
    "  per_device_eval_batch_size=10,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  logging_strategy=\"epoch\",\n",
    "  num_train_epochs=10,\n",
    "  fp16=True,\n",
    "  learning_rate=2e-5,\n",
    "#   dataloader_num_workers=20,lr\n",
    "\n",
    "  save_total_limit=1,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='wandb',\n",
    "  load_best_model_at_end=True,\n",
    "#   metric_for_best_model=\"score\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_fashion_data,\n",
    "    eval_dataset=val_fashion_data,\n",
    "    # data_collator=collate_fn,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "trainer.add_callback(CustomCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dccb554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-10 20:09:54,564] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aseems/anaconda3/envs/mhcp4/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaran21258\u001b[0m (\u001b[33mkaran912\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aseems/ml/mchl/wandb/run-20241110_200958-33s8ip01</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karan912/huggingface/runs/33s8ip01' target=\"_blank\">./blip/Sarees</a></strong> to <a href='https://wandb.ai/karan912/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karan912/huggingface' target=\"_blank\">https://wandb.ai/karan912/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karan912/huggingface/runs/33s8ip01' target=\"_blank\">https://wandb.ai/karan912/huggingface/runs/33s8ip01</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/400 02:56 < 07:15, 0.65 it/s, Epoch 2.90/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.204900</td>\n",
       "      <td>7.012710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.170900</td>\n",
       "      <td>5.382658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a1a5b976384bebae86e14b2bee5702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '2', '', '0', '0', '', '', '', '2', '', '', '0', '', '0', '', '', '', '', '', '', '0', '1', '0', '0', '', '', '0', '', '0', '0', '', '2', '0', '1', '', '0', '3', '0', '', '', '', '', '', '0', '0', '0', '0', '0', '', '0', '3', '', '0', '', '', '1', '', '', '', '0', '', '', '0', '', '', '', '', '0', '', '', '', '', '', '', '0', '2', '', '', '0', '', '', '0', '0', '', '', '0', '2', '', '0', '', '0', '', '0', '', '', '2', '0', '0', '2', '']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00        54\n",
      "           0       0.34      1.00      0.51        34\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.34       100\n",
      "   macro avg       0.07      0.20      0.10       100\n",
      "weighted avg       0.12      0.34      0.17       100\n",
      "\n",
      "\n",
      "\n",
      "{'score': 0.15632183908045977}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e566759c974c47e3b278c4b877cb37ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '2', '', '0', '0', '', '', '', '2', '', '', '0', '', '0', '', '', '', '', '', '', '0', '1', '0', '0', '', '', '0', '', '0', '0', '', '2', '0', '1', '', '0', '3', '0', '', '', '', '', '', '0', '0', '0', '0', '0', '', '0', '3', '', '0', '', '', '1', '', '', '', '0', '', '', '0', '', '', '', '', '0', '', '', '', '', '', '', '0', '2', '', '', '0', '', '', '0', '0', '', '', '0', '2', '', '0', '', '0', '', '0', '', '', '2', '0', '0', '2', '']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00        54\n",
      "           0       0.34      1.00      0.51        34\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.34       100\n",
      "   macro avg       0.07      0.20      0.10       100\n",
      "weighted avg       0.12      0.34      0.17       100\n",
      "\n",
      "\n",
      "\n",
      "{'score': 0.15632183908045977}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./blip/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/final\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2390\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m-> 2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(f\"./blip/{category}/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3474278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caf73c5042a49ea9628659193351bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "['', '0', '0', '', '0', '', '0', '', '0', '0', '', '', '2', '0', '0', '1', '', '0', '', '0']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "['', '0', '0', '', '0', '', '0', '', '0', '0', '', '', '2', '0', '0', '1', '', '0', '', '0']\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00         8\n",
      "           0       0.50      1.00      0.67        10\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.12      0.25      0.17        20\n",
      "weighted avg       0.25      0.50      0.33        20\n",
      "\n",
      "\n",
      "\n",
      "{'score': 0.25}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.505589485168457,\n",
       " 'eval_runtime': 3.1286,\n",
       " 'eval_samples_per_second': 6.393,\n",
       " 'eval_steps_per_second': 6.393,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(val_fashion_data)\n",
    "#1-54(imbalance),2-65,3-85,5-56,6-70,7-52(imbalance),8-51(imbalance),9-60(imbalance),10-49(imbalance)\n",
    "#4-30,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhcp4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
