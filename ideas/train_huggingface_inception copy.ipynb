{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08046f22-db0f-45bb-8aa5-18309a23a1e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:23.940808Z",
     "iopub.status.busy": "2024-10-14T11:28:23.940248Z",
     "iopub.status.idle": "2024-10-14T11:28:26.614016Z",
     "shell.execute_reply": "2024-10-14T11:28:26.613452Z",
     "shell.execute_reply.started": "2024-10-14T11:28:23.940788Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel\n",
    "from torchinfo import summary  # \n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import EfficientNetForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3438730c-888d-4fd7-b57e-8ff63ab4f94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.616389Z",
     "iopub.status.busy": "2024-10-14T11:28:26.616065Z",
     "iopub.status.idle": "2024-10-14T11:28:26.620522Z",
     "shell.execute_reply": "2024-10-14T11:28:26.619968Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.616371Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\"\n",
    "def setAllSeeds(seed):\n",
    "  os.environ['MY_GLOBAL_SEED'] = str(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "# setAllSeeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a86c36-a933-42bf-92c1-bd6cfbf0975b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.625620Z",
     "iopub.status.busy": "2024-10-14T11:28:26.625171Z",
     "iopub.status.idle": "2024-10-14T11:28:26.717777Z",
     "shell.execute_reply": "2024-10-14T11:28:26.717238Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.625599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Men Tshirts' 'Sarees' 'Kurtis' 'Women Tshirts' 'Women Tops & Tunics']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "categories=df[\"Category\"].unique()\n",
    "print(categories)\n",
    "category=categories[1]\n",
    "df = df[df[\"Category\"]==category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94a5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"test.csv\")\n",
    "test_df=test_df[test_df[\"Category\"]==category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c43f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "Category        0\n",
       "len             0\n",
       "attr_1      10461\n",
       "attr_2        667\n",
       "attr_3       2485\n",
       "attr_4        450\n",
       "attr_5        697\n",
       "attr_6      13336\n",
       "attr_7       9450\n",
       "attr_8       1881\n",
       "attr_9       4043\n",
       "attr_10       528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae75c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr_i=1\n",
    "# removing_attri=[]\n",
    "# df.iloc[:,3:2+attr_i]=np.nan\n",
    "# df.iloc[:,3+attr_i:]=np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8232843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id     Category  len  attr_1         attr_2        attr_3        attr_4      attr_5       attr_6               attr_7         attr_8        attr_9        attr_10\n",
      "7432   Sarees    10   same as saree  woven design  small border  multicolor  party        jacquard             woven design   zari woven    applique      no         1\n",
      "19478  Sarees    10   same as saree  woven design  small border  multicolor  party        jacquard             woven design   zari woven    applique      no         1\n",
      "19418  Sarees    10   same as saree  zari          small border  cream       party        jacquard             woven design   zari woven    elephant      yes        1\n",
      "19436  Sarees    10   same as saree  zari          big border    multicolor  daily        tassels and latkans  default        woven design  checked       no         1\n",
      "19445  Sarees    10   default        zari          big border    cream       traditional  jacquard             default        zari woven    ethnic motif  no         1\n",
      "                                                                                                                                                                    ..\n",
      "13288  Sarees    10   same as saree  zari          small border  cream       party        jacquard             woven design   zari woven    floral        no         1\n",
      "13285  Sarees    10   same as saree  zari          big border    multicolor  party        tassels and latkans  default        printed       checked       no         1\n",
      "13284  Sarees    10   same as saree  woven design  small border  multicolor  party        jacquard             woven design   zari woven    applique      no         1\n",
      "13261  Sarees    10   same as saree  zari          small border  cream       traditional  jacquard             woven design   zari woven    peacock       no         1\n",
      "25763  Sarees    10   default        woven design  big border    multicolor  daily        tassels and latkans  same as saree  zari woven    default       no         1\n",
      "Name: count, Length: 2237, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "218fb75d-1b90-416b-9a41-288de39def1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.719372Z",
     "iopub.status.busy": "2024-10-14T11:28:26.719005Z",
     "iopub.status.idle": "2024-10-14T11:28:26.725099Z",
     "shell.execute_reply": "2024-10-14T11:28:26.724553Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.719356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['same as saree' 'solid' 'same as border' 'default']\n",
      "['woven design' 'zari' 'no border' 'solid' 'default' 'temple border']\n",
      "['small border' 'big border' 'no border']\n",
      "['multicolor' 'cream' 'white' 'default' 'navy blue' 'yellow' 'green'\n",
      " 'pink']\n",
      "['party' 'traditional' 'daily' 'wedding']\n",
      "['jacquard' 'default' 'tassels and latkans']\n",
      "['woven design' 'same as saree' 'default' 'zari woven']\n",
      "['zari woven' 'woven design' 'default' 'solid' 'printed']\n",
      "['applique' 'elephant' 'floral' 'ethnic motif' 'peacock' 'default' 'solid'\n",
      " 'checked' 'botanical']\n",
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "delCol = []\n",
    "idxCol = []\n",
    "trackNum = []\n",
    "weights=[]\n",
    "m=nn.Softmax(dim=1)\n",
    "l=[]\n",
    "for i in range(1,11):\n",
    "    uniName = df[\"attr_\"+str(i)].dropna().unique()\n",
    "    print(uniName)\n",
    "    if(len(uniName)==0):\n",
    "        delCol.append(\"attr_\"+str(i))\n",
    "    else:\n",
    "        idxCol.append(\"attr_\"+str(i))\n",
    "        l.append('attr_'+str(i))\n",
    "        trackNum.append(len(uniName))\n",
    "        class_weights=compute_class_weight(class_weight=\"balanced\",classes=uniName,y=df[\"attr_\"+str(i)].dropna())\n",
    "        weights.append(torch.tensor([1]*len(uniName),dtype=torch.float32).to(DEVICE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d305da-99e2-424a-b774-b1ffdbd56fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.732549Z",
     "iopub.status.busy": "2024-10-14T11:28:26.732338Z",
     "iopub.status.idle": "2024-10-14T11:28:26.736656Z",
     "shell.execute_reply": "2024-10-14T11:28:26.736114Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.732533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18346, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(delCol,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ce1ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "Category        0\n",
       "len             0\n",
       "attr_1      10461\n",
       "attr_2        667\n",
       "attr_3       2485\n",
       "attr_4        450\n",
       "attr_5        697\n",
       "attr_6      13336\n",
       "attr_7       9450\n",
       "attr_8       1881\n",
       "attr_9       4043\n",
       "attr_10       528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a251fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df2da111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 'same as saree', 1: 'solid', 2: 'same as border', 3: 'default'}, 1: {0: 'woven design', 1: 'zari', 2: 'no border', 3: 'solid', 4: 'default', 5: 'temple border'}, 2: {0: 'small border', 1: 'big border', 2: 'no border'}, 3: {0: 'multicolor', 1: 'cream', 2: 'white', 3: 'default', 4: 'navy blue', 5: 'yellow', 6: 'green', 7: 'pink'}, 4: {0: 'party', 1: 'traditional', 2: 'daily', 3: 'wedding'}, 5: {0: 'jacquard', 1: 'default', 2: 'tassels and latkans'}, 6: {0: 'woven design', 1: 'same as saree', 2: 'default', 3: 'zari woven'}, 7: {0: 'zari woven', 1: 'woven design', 2: 'default', 3: 'solid', 4: 'printed'}, 8: {0: 'applique', 1: 'elephant', 2: 'floral', 3: 'ethnic motif', 4: 'peacock', 5: 'default', 6: 'solid', 7: 'checked', 8: 'botanical'}, 9: {0: 'no', 1: 'yes'}}\n",
      "{0: {'same as saree': 0, 'solid': 1, 'same as border': 2, 'default': 3}, 1: {'woven design': 0, 'zari': 1, 'no border': 2, 'solid': 3, 'default': 4, 'temple border': 5}, 2: {'small border': 0, 'big border': 1, 'no border': 2}, 3: {'multicolor': 0, 'cream': 1, 'white': 2, 'default': 3, 'navy blue': 4, 'yellow': 5, 'green': 6, 'pink': 7}, 4: {'party': 0, 'traditional': 1, 'daily': 2, 'wedding': 3}, 5: {'jacquard': 0, 'default': 1, 'tassels and latkans': 2}, 6: {'woven design': 0, 'same as saree': 1, 'default': 2, 'zari woven': 3}, 7: {'zari woven': 0, 'woven design': 1, 'default': 2, 'solid': 3, 'printed': 4}, 8: {'applique': 0, 'elephant': 1, 'floral': 2, 'ethnic motif': 3, 'peacock': 4, 'default': 5, 'solid': 6, 'checked': 7, 'botanical': 8}, 9: {'no': 0, 'yes': 1}}\n",
      "{0: 'attr_1', 1: 'attr_2', 2: 'attr_3', 3: 'attr_4', 4: 'attr_5', 5: 'attr_6', 6: 'attr_7', 7: 'attr_8', 8: 'attr_9', 9: 'attr_10'}\n"
     ]
    }
   ],
   "source": [
    "id2label={}\n",
    "label2id={}\n",
    "attrs={}\n",
    "total_attr=len(df.columns)\n",
    "for i in range(3,total_attr):\n",
    "    labels=df[df.columns[i]].dropna().unique()\n",
    "    # print(df.columns[i],labels)\n",
    "    id2label[i-3]={k:labels[k] for k in range(len(labels))}\n",
    "    label2id[i-3]={labels[k]:k for k in range(len(labels))}\n",
    "    attrs[i-3]=df.columns[i]\n",
    "print(id2label)\n",
    "print(label2id)\n",
    "print(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f394a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>7432</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>7433</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>7434</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7435</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>7436</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Category  len  attr_1  attr_2  attr_3  attr_4  attr_5  attr_6  \\\n",
       "7267  7432   Sarees   10       0       0       0       0       0       0   \n",
       "7268  7433   Sarees   10    -100       1       0       1       1    -100   \n",
       "7269  7434   Sarees   10    -100       1       0       2       0    -100   \n",
       "7270  7435   Sarees   10       0       0       1       3       1    -100   \n",
       "7271  7436   Sarees   10       1       2    -100    -100       2    -100   \n",
       "\n",
       "      attr_7  attr_8  attr_9  attr_10  \n",
       "7267       0       0       0        0  \n",
       "7268    -100       0       1        0  \n",
       "7269    -100       0       2        0  \n",
       "7270       1       0       3        0  \n",
       "7271    -100    -100    -100        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(example):\n",
    "    for i in attrs:\n",
    "        # print(example[attrs[i]],type(example[attrs[i]]),pd.isna(example[attrs[i]]))\n",
    "        if not pd.isna(example[attrs[i]]):\n",
    "            example[attrs[i]]=label2id[i][example[attrs[i]]]\n",
    "        else:\n",
    "            example[attrs[i]]=-100\n",
    "    return example\n",
    "df=df.apply(categorize,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1df7b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "Category    0\n",
       "len         0\n",
       "attr_1      0\n",
       "attr_2      0\n",
       "attr_3      0\n",
       "attr_4      0\n",
       "attr_5      0\n",
       "attr_6      0\n",
       "attr_7      0\n",
       "attr_8      0\n",
       "attr_9      0\n",
       "attr_10     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778a3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d886c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332990dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# min_count = train_df[f'attr_{attr_i}'].value_counts().min()\n",
    "# print(f\"The minimum count across all categories is: {min_count}\")\n",
    "# df_sampled = train_df.groupby(f'attr_{attr_i}').sample(n=min_count, random_state=42)\n",
    "# train_df = df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "933021b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_1\n",
      "-100    9415\n",
      " 0      4691\n",
      " 2      1456\n",
      " 3       772\n",
      " 1       177\n",
      "Name: count, dtype: int64\n",
      "attr_2\n",
      " 1      7662\n",
      " 0      5643\n",
      " 5      1162\n",
      " 4       773\n",
      "-100     607\n",
      " 3       371\n",
      " 2       293\n",
      "Name: count, dtype: int64\n",
      "attr_3\n",
      " 0      8565\n",
      " 1      5184\n",
      "-100    2248\n",
      " 2       514\n",
      "Name: count, dtype: int64\n",
      "attr_4\n",
      " 0      4623\n",
      " 1      4314\n",
      " 3      3665\n",
      " 2      2408\n",
      "-100     411\n",
      " 7       313\n",
      " 4       304\n",
      " 5       245\n",
      " 6       228\n",
      "Name: count, dtype: int64\n",
      "attr_5\n",
      " 0      9389\n",
      " 1      4442\n",
      " 2      1204\n",
      " 3       846\n",
      "-100     630\n",
      "Name: count, dtype: int64\n",
      "attr_6\n",
      "-100    12001\n",
      " 0       3769\n",
      " 1        492\n",
      " 2        249\n",
      "Name: count, dtype: int64\n",
      "attr_7\n",
      "-100    8497\n",
      " 0      3343\n",
      " 3      2412\n",
      " 1      1911\n",
      " 2       348\n",
      "Name: count, dtype: int64\n",
      "attr_8\n",
      " 0      12174\n",
      "-100     1699\n",
      " 3        984\n",
      " 1        732\n",
      " 2        714\n",
      " 4        208\n",
      "Name: count, dtype: int64\n",
      "attr_9\n",
      "-100    3652\n",
      " 5      2944\n",
      " 3      2643\n",
      " 4      2335\n",
      " 2      2241\n",
      " 6      1004\n",
      " 1       639\n",
      " 0       571\n",
      " 7       258\n",
      " 8       224\n",
      "Name: count, dtype: int64\n",
      "attr_10\n",
      " 0      13374\n",
      " 1       2659\n",
      "-100      478\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3100d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights[4]=torch.tensor([1,20],dtype=torch.float32).to(DEVICE)\n",
    "# weights[9]=torch.tensor([1,1,1,1,3,2],dtype=torch.float32).to(DEVICE)\n",
    "# weights[7]=torch.tensor([1,10],dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e10ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in l:\n",
    "#     print(i)\n",
    "#     for j in set(train_df[i].unique()):\n",
    "#         x=train_df[i][train_df[i]==j]\n",
    "#         if x.count()<300 and j!=-100:\n",
    "#             y=train_df[train_df[i]==j]\n",
    "#             y.iloc[:,3:]=-100\n",
    "#             y[i]=j\n",
    "#             print(y)\n",
    "#             train_df=pd.concat([train_df,y,y]).reset_index(drop=True)\n",
    "# for i in l:\n",
    "#     print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36416a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14469</th>\n",
       "      <td>14634</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21667</th>\n",
       "      <td>21832</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24382</th>\n",
       "      <td>24547</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17978</th>\n",
       "      <td>18143</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20916</th>\n",
       "      <td>21081</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category  len  attr_1  attr_2  attr_3  attr_4  attr_5  attr_6  \\\n",
       "14469  14634   Sarees   10       3       1       1       3       1    -100   \n",
       "21667  21832   Sarees   10    -100       0    -100       0       2    -100   \n",
       "24382  24547   Sarees   10    -100       1       0       1       1    -100   \n",
       "17978  18143   Sarees   10    -100       1       1       6       1    -100   \n",
       "20916  21081   Sarees   10       0       0       0       0       0       0   \n",
       "\n",
       "       attr_7  attr_8  attr_9  attr_10  \n",
       "14469    -100       0       3        0  \n",
       "21667    -100    -100    -100        0  \n",
       "24382    -100       0       2        0  \n",
       "17978    -100       0       1        0  \n",
       "20916       0       0    -100        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80a27462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df[f'attr_{attr_i}'].value_counts())\n",
    "# print(val_df[f'attr_{attr_i}'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfedae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "# model_name = 'google/vit-base-patch16-224'\n",
    "# model_name=f\"vit5/{category}/final\"\n",
    "# model_name = 'google/efficientnet-b0'\n",
    "# model_name = 'vit6/'+category+'/final'\n",
    "# model_name=\"google/vit-large-patch16-224\"\n",
    "# model_name=\"Shadowking912/inception_v3\"\n",
    "model_name=\"vit6/\"+category+\"/final\"\n",
    "# processor = AutoImageProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113befc-d9c0-427e-98c8-467977f0f7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.751798Z",
     "iopub.status.busy": "2024-10-14T11:28:26.751660Z",
     "iopub.status.idle": "2024-10-14T11:28:26.756144Z",
     "shell.execute_reply": "2024-10-14T11:28:26.755669Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.751778Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomFashionManager(Dataset):\n",
    "    def __init__(self,csv_file, root_dir=\"./\",transforms=None):\n",
    "        self.fashionItems = csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fashionItems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,f\"{self.fashionItems.iloc[idx, 0]:06d}\"+'.jpg')\n",
    "        image = Image.open(img_name)\n",
    "        attributes = self.fashionItems.iloc[idx, 3:]\n",
    "        attributes = np.array(attributes)\n",
    "        attributes = attributes.astype('float')\n",
    "        \n",
    "        # inputs=processor(image, return_tensors='pt')\n",
    "        inputs={}\n",
    "        # inputs['labels']=torch.tensor(attributes, dtype=torch.long)\n",
    "        inputs['pixel_values'] = self.transforms(image).unsqueeze(0)\n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "798bdc15-2101-4eb7-a52f-6748fd70d5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:26.756919Z",
     "iopub.status.busy": "2024-10-14T11:28:26.756780Z",
     "iopub.status.idle": "2024-10-14T11:28:27.051779Z",
     "shell.execute_reply": "2024-10-14T11:28:27.051275Z",
     "shell.execute_reply.started": "2024-10-14T11:28:26.756906Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transformations=transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# transformations=None\n",
    "train_fashion_data = CustomFashionManager(csv_file=train_df,\n",
    "                                    root_dir='train_images',transforms=transformations)\n",
    "val_fashion_data = CustomFashionManager(csv_file=val_df,\n",
    "                                    root_dir='train_images',transforms=transformations)\n",
    "test_fashion_data = CustomFashionManager(csv_file=test_df,root_dir='test_images',transforms=transformations)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d3d845-6704-4cc0-acdd-a12ee3f1f8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T11:28:27.578464Z",
     "iopub.status.busy": "2024-10-14T11:28:27.578296Z",
     "iopub.status.idle": "2024-10-14T11:28:28.848764Z",
     "shell.execute_reply": "2024-10-14T11:28:28.848059Z",
     "shell.execute_reply.started": "2024-10-14T11:28:27.578419Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "from transformers import (\n",
    "    ViTConfig,ViTPreTrainedModel,EfficientNetConfig,EfficientNetPreTrainedModel,\n",
    "    EfficientNetModel,PretrainedConfig,PreTrainedModel)\n",
    "from torchvision import models\n",
    "\n",
    "class CustomConfig(PretrainedConfig):\n",
    "    def __init__(self,num_classes_per_label:List[int]=[1],**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes_per_label = num_classes_per_label\n",
    "\n",
    "            \n",
    "class MultiLabelMultiClassViT(PreTrainedModel):\n",
    "    config_class=CustomConfig\n",
    "    def __init__(self, config: CustomConfig,pretrain=False) -> None:\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.model = models.inception_v3(pretrained=pretrain)\n",
    "        \n",
    "        self.classifiers = nn.ModuleList([\n",
    "            # nn.Sequential(nn.Dropout(0.2),\n",
    "            # nn.Linear(config.hidden_size, 32),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(self.model.fc.in_features, num_classes)\n",
    "            for num_classes in config.num_classes_per_label\n",
    "        ])\n",
    "        self.classifiers2 = nn.ModuleList([\n",
    "            # nn.Sequential(nn.Dropout(0.2),\n",
    "            # nn.Linear(config.hidden_size, 32),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(self.model.AuxLogits.fc.in_features, num_classes)\n",
    "            for num_classes in config.num_classes_per_label\n",
    "        ])\n",
    "        self.model.fc=nn.Identity()\n",
    "        self.model.AuxLogits.fc=nn.Identity()\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, pixel_values,labels=None):\n",
    "        # outputs = self.efficientnet(pixel_values).last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        # outputs = outputs.reshape(outputs.shape[0],-1)\n",
    "        if self.training:\n",
    "            outputs,aux=self.model(pixel_values)\n",
    "            logits = [classifier(outputs) for classifier in self.classifiers]\n",
    "            aux_logits = [classifier(aux) for classifier in self.classifiers2]\n",
    "        else:\n",
    "            outputs=self.model(pixel_values)\n",
    "            logits = [classifier(outputs) for classifier in self.classifiers]\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss=0\n",
    "            # loss_weights=np.array([1,1,1,1,1,1,1,5])\n",
    "            # loss_weights=loss_weights/loss_weights.sum()\n",
    "            for i in range(len(logits)):\n",
    "                target=labels[:,i]\n",
    "                loss += torch.nn.functional.cross_entropy(logits[i], target,ignore_index=-100)\n",
    "                if self.training:\n",
    "                    loss +=0.4*torch.nn.functional.cross_entropy(aux_logits[i], target,ignore_index=-100)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "    \n",
    "# Example usage\n",
    "num_labels = len(trackNum)  # For example, 5 different labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "871286a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MultiLabelMultiClassViT                  --\n",
      "├─Inception3: 1-1                        --\n",
      "│    └─BasicConv2d: 2-1                  --\n",
      "│    │    └─Conv2d: 3-1                  864\n",
      "│    │    └─BatchNorm2d: 3-2             64\n",
      "│    └─BasicConv2d: 2-2                  --\n",
      "│    │    └─Conv2d: 3-3                  9,216\n",
      "│    │    └─BatchNorm2d: 3-4             64\n",
      "│    └─BasicConv2d: 2-3                  --\n",
      "│    │    └─Conv2d: 3-5                  18,432\n",
      "│    │    └─BatchNorm2d: 3-6             128\n",
      "│    └─MaxPool2d: 2-4                    --\n",
      "│    └─BasicConv2d: 2-5                  --\n",
      "│    │    └─Conv2d: 3-7                  5,120\n",
      "│    │    └─BatchNorm2d: 3-8             160\n",
      "│    └─BasicConv2d: 2-6                  --\n",
      "│    │    └─Conv2d: 3-9                  138,240\n",
      "│    │    └─BatchNorm2d: 3-10            384\n",
      "│    └─MaxPool2d: 2-7                    --\n",
      "│    └─InceptionA: 2-8                   --\n",
      "│    │    └─BasicConv2d: 3-11            12,416\n",
      "│    │    └─BasicConv2d: 3-12            9,312\n",
      "│    │    └─BasicConv2d: 3-13            76,928\n",
      "│    │    └─BasicConv2d: 3-14            12,416\n",
      "│    │    └─BasicConv2d: 3-15            55,488\n",
      "│    │    └─BasicConv2d: 3-16            83,136\n",
      "│    │    └─BasicConv2d: 3-17            6,208\n",
      "│    └─InceptionA: 2-9                   --\n",
      "│    │    └─BasicConv2d: 3-18            16,512\n",
      "│    │    └─BasicConv2d: 3-19            12,384\n",
      "│    │    └─BasicConv2d: 3-20            76,928\n",
      "│    │    └─BasicConv2d: 3-21            16,512\n",
      "│    │    └─BasicConv2d: 3-22            55,488\n",
      "│    │    └─BasicConv2d: 3-23            83,136\n",
      "│    │    └─BasicConv2d: 3-24            16,512\n",
      "│    └─InceptionA: 2-10                  --\n",
      "│    │    └─BasicConv2d: 3-25            18,560\n",
      "│    │    └─BasicConv2d: 3-26            13,920\n",
      "│    │    └─BasicConv2d: 3-27            76,928\n",
      "│    │    └─BasicConv2d: 3-28            18,560\n",
      "│    │    └─BasicConv2d: 3-29            55,488\n",
      "│    │    └─BasicConv2d: 3-30            83,136\n",
      "│    │    └─BasicConv2d: 3-31            18,560\n",
      "│    └─InceptionB: 2-11                  --\n",
      "│    │    └─BasicConv2d: 3-32            996,096\n",
      "│    │    └─BasicConv2d: 3-33            18,560\n",
      "│    │    └─BasicConv2d: 3-34            55,488\n",
      "│    │    └─BasicConv2d: 3-35            83,136\n",
      "│    └─InceptionC: 2-12                  --\n",
      "│    │    └─BasicConv2d: 3-36            147,840\n",
      "│    │    └─BasicConv2d: 3-37            98,560\n",
      "│    │    └─BasicConv2d: 3-38            114,944\n",
      "│    │    └─BasicConv2d: 3-39            172,416\n",
      "│    │    └─BasicConv2d: 3-40            98,560\n",
      "│    │    └─BasicConv2d: 3-41            114,944\n",
      "│    │    └─BasicConv2d: 3-42            114,944\n",
      "│    │    └─BasicConv2d: 3-43            114,944\n",
      "│    │    └─BasicConv2d: 3-44            172,416\n",
      "│    │    └─BasicConv2d: 3-45            147,840\n",
      "│    └─InceptionC: 2-13                  --\n",
      "│    │    └─BasicConv2d: 3-46            147,840\n",
      "│    │    └─BasicConv2d: 3-47            123,200\n",
      "│    │    └─BasicConv2d: 3-48            179,520\n",
      "│    │    └─BasicConv2d: 3-49            215,424\n",
      "│    │    └─BasicConv2d: 3-50            123,200\n",
      "│    │    └─BasicConv2d: 3-51            179,520\n",
      "│    │    └─BasicConv2d: 3-52            179,520\n",
      "│    │    └─BasicConv2d: 3-53            179,520\n",
      "│    │    └─BasicConv2d: 3-54            215,424\n",
      "│    │    └─BasicConv2d: 3-55            147,840\n",
      "│    └─InceptionC: 2-14                  --\n",
      "│    │    └─BasicConv2d: 3-56            147,840\n",
      "│    │    └─BasicConv2d: 3-57            123,200\n",
      "│    │    └─BasicConv2d: 3-58            179,520\n",
      "│    │    └─BasicConv2d: 3-59            215,424\n",
      "│    │    └─BasicConv2d: 3-60            123,200\n",
      "│    │    └─BasicConv2d: 3-61            179,520\n",
      "│    │    └─BasicConv2d: 3-62            179,520\n",
      "│    │    └─BasicConv2d: 3-63            179,520\n",
      "│    │    └─BasicConv2d: 3-64            215,424\n",
      "│    │    └─BasicConv2d: 3-65            147,840\n",
      "│    └─InceptionC: 2-15                  --\n",
      "│    │    └─BasicConv2d: 3-66            147,840\n",
      "│    │    └─BasicConv2d: 3-67            147,840\n",
      "│    │    └─BasicConv2d: 3-68            258,432\n",
      "│    │    └─BasicConv2d: 3-69            258,432\n",
      "│    │    └─BasicConv2d: 3-70            147,840\n",
      "│    │    └─BasicConv2d: 3-71            258,432\n",
      "│    │    └─BasicConv2d: 3-72            258,432\n",
      "│    │    └─BasicConv2d: 3-73            258,432\n",
      "│    │    └─BasicConv2d: 3-74            258,432\n",
      "│    │    └─BasicConv2d: 3-75            147,840\n",
      "│    └─InceptionAux: 2-16                --\n",
      "│    │    └─BasicConv2d: 3-76            98,560\n",
      "│    │    └─BasicConv2d: 3-77            2,459,136\n",
      "│    │    └─Identity: 3-78               --\n",
      "│    └─InceptionD: 2-17                  --\n",
      "│    │    └─BasicConv2d: 3-79            147,840\n",
      "│    │    └─BasicConv2d: 3-80            553,600\n",
      "│    │    └─BasicConv2d: 3-81            147,840\n",
      "│    │    └─BasicConv2d: 3-82            258,432\n",
      "│    │    └─BasicConv2d: 3-83            258,432\n",
      "│    │    └─BasicConv2d: 3-84            332,160\n",
      "│    └─InceptionE: 2-18                  --\n",
      "│    │    └─BasicConv2d: 3-85            410,240\n",
      "│    │    └─BasicConv2d: 3-86            492,288\n",
      "│    │    └─BasicConv2d: 3-87            443,136\n",
      "│    │    └─BasicConv2d: 3-88            443,136\n",
      "│    │    └─BasicConv2d: 3-89            574,336\n",
      "│    │    └─BasicConv2d: 3-90            1,549,056\n",
      "│    │    └─BasicConv2d: 3-91            443,136\n",
      "│    │    └─BasicConv2d: 3-92            443,136\n",
      "│    │    └─BasicConv2d: 3-93            246,144\n",
      "│    └─InceptionE: 2-19                  --\n",
      "│    │    └─BasicConv2d: 3-94            656,000\n",
      "│    │    └─BasicConv2d: 3-95            787,200\n",
      "│    │    └─BasicConv2d: 3-96            443,136\n",
      "│    │    └─BasicConv2d: 3-97            443,136\n",
      "│    │    └─BasicConv2d: 3-98            918,400\n",
      "│    │    └─BasicConv2d: 3-99            1,549,056\n",
      "│    │    └─BasicConv2d: 3-100           443,136\n",
      "│    │    └─BasicConv2d: 3-101           443,136\n",
      "│    │    └─BasicConv2d: 3-102           393,600\n",
      "│    └─AdaptiveAvgPool2d: 2-20           --\n",
      "│    └─Dropout: 2-21                     --\n",
      "│    └─Identity: 2-22                    --\n",
      "├─ModuleList: 1-2                        --\n",
      "│    └─Linear: 2-23                      8,196\n",
      "│    └─Linear: 2-24                      12,294\n",
      "│    └─Linear: 2-25                      6,147\n",
      "│    └─Linear: 2-26                      16,392\n",
      "│    └─Linear: 2-27                      8,196\n",
      "│    └─Linear: 2-28                      6,147\n",
      "│    └─Linear: 2-29                      8,196\n",
      "│    └─Linear: 2-30                      10,245\n",
      "│    └─Linear: 2-31                      18,441\n",
      "│    └─Linear: 2-32                      4,098\n",
      "├─ModuleList: 1-3                        --\n",
      "│    └─Linear: 2-33                      3,076\n",
      "│    └─Linear: 2-34                      4,614\n",
      "│    └─Linear: 2-35                      2,307\n",
      "│    └─Linear: 2-36                      6,152\n",
      "│    └─Linear: 2-37                      3,076\n",
      "│    └─Linear: 2-38                      2,307\n",
      "│    └─Linear: 2-39                      3,076\n",
      "│    └─Linear: 2-40                      3,845\n",
      "│    └─Linear: 2-41                      6,921\n",
      "│    └─Linear: 2-42                      1,538\n",
      "=================================================================\n",
      "Total params: 24,478,528\n",
      "Trainable params: 24,478,528\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# config=EfficientNetConfig.from_pretrained(model_name)\n",
    "# config=CustomConfig(num_classes_per_label=trackNum)\n",
    "# model = MultiLabelMultiClassViT.from_pretrained(model_name, config=config)\n",
    "# # model.model.aux_logits=False\n",
    "\n",
    "model=MultiLabelMultiClassViT.from_pretrained(model_name)\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "batch_size = 32\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.cat([x['pixel_values'] for x in batch],dim=0),\n",
    "        # 'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits = pred.predictions\n",
    "    labels=pred.label_ids\n",
    "    probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "    probs=probs.T\n",
    "    f1s=[]\n",
    "    for i in range(labels.shape[1]):\n",
    "        non_padding_indices = [j for j, label in enumerate(labels[:,i]) if label != -100]\n",
    "        labels_ = [labels[j,i] for j in non_padding_indices]\n",
    "        probs_ = [probs[j,i] for j in non_padding_indices]\n",
    "        micro=f1_score(labels_,probs_,average='micro')\n",
    "        macro=f1_score(labels_,probs_,average='macro')\n",
    "        print(f\"attr_{i} f1 score: {macro}\")\n",
    "        # print(classification_report(labels_,probs_))\n",
    "        score=2*(micro*macro)/(micro+macro)\n",
    "        f1s.append(score)\n",
    "    print()\n",
    "    print()\n",
    "    return {'score': sum(f1s)/len(f1s)}\n",
    "\n",
    "\n",
    "    # logits = pred.predictions\n",
    "    # labels=pred.label_ids\n",
    "    # probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "    # probs=probs.T\n",
    "    # labels=labels.flatten()\n",
    "    # probs=probs.flatten()\n",
    "    # non_padding_indices = [i for i, label in enumerate(labels) if label != -100]\n",
    "    # labels = [labels[i] for i in non_padding_indices]\n",
    "    # probs = [probs[i] for i in non_padding_indices]\n",
    "    # print(classification_report(labels,probs))\n",
    "    # report=classification_report(labels,probs,output_dict=True)\n",
    "    # return {'accuracy': report['accuracy'],\"macro avg f1\":report['macro avg']['f1-score']}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit6/\"+category,\n",
    "  per_device_train_batch_size=128,\n",
    "  per_device_eval_batch_size=128,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  logging_strategy=\"epoch\",\n",
    "  num_train_epochs=10,\n",
    "  bf16=True,\n",
    "  learning_rate=2e-4,\n",
    "#   dataloader_num_workers=20,lr\n",
    "  save_total_limit=1,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='wandb',\n",
    "  load_best_model_at_end=True,\n",
    "  metric_for_best_model=\"score\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_fashion_data,\n",
    "    eval_dataset=val_fashion_data,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-16 23:42:29,768] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aseems/anaconda3/envs/mhcp4/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_0 f1 score: 0.4460195680365554\n",
      "attr_1 f1 score: 0.6607053541728461\n",
      "attr_2 f1 score: 0.8411579467863991\n",
      "attr_3 f1 score: 0.42318080336469294\n",
      "attr_4 f1 score: 0.5020157989732551\n",
      "attr_5 f1 score: 0.5530085320852677\n",
      "attr_6 f1 score: 0.5248556597209413\n",
      "attr_7 f1 score: 0.46377664041564426\n",
      "attr_8 f1 score: 0.593492290796093\n",
      "attr_9 f1 score: 0.46222352391407967\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaran21258\u001b[0m (\u001b[33mkaran912\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aseems/ml/mchl/wandb/run-20241116_234305-6ck93cp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karan912/huggingface/runs/6ck93cp1' target=\"_blank\">./vit6/Sarees</a></strong> to <a href='https://wandb.ai/karan912/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karan912/huggingface' target=\"_blank\">https://wandb.ai/karan912/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karan912/huggingface/runs/6ck93cp1' target=\"_blank\">https://wandb.ai/karan912/huggingface/runs/6ck93cp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.8802642822265625,\n",
       " 'eval_model_preparation_time': 0.0076,\n",
       " 'eval_score': 0.6291425042174301,\n",
       " 'eval_runtime': 33.7381,\n",
       " 'eval_samples_per_second': 54.39,\n",
       " 'eval_steps_per_second': 0.445}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()\n",
    "# trainer.save_model(f\"./vit6/{category}/final\")\n",
    "# trainer.evaluate(val_fashion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3474278",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_fashion_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m logits \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[1;32m      3\u001b[0m probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39margmax(logit,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m logit \u001b[38;5;129;01min\u001b[39;00m logits])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:3946\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3943\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3945\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3946\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3949\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:4051\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4048\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4050\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 4051\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   4052\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   4053\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   4054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/data_loader.py:561\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m--> 561\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m, in \u001b[0;36mCustomFashionManager.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m inputs\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m     22\u001b[0m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(attributes, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m---> 23\u001b[0m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred=trainer.predict(test_fashion_data)\n",
    "logits = y_pred.predictions\n",
    "probs = np.stack([np.argmax(logit,axis=1) for logit in logits])\n",
    "probs=probs.T\n",
    "l=[]\n",
    "for i in range(len(probs)):\n",
    "    x=[]\n",
    "    for j in range(len(probs[i])):\n",
    "        x.append(id2label[j][probs[i][j]])\n",
    "    l.append(x)\n",
    "\n",
    "test_df['len']=len(l[0])\n",
    "for i in range(10):\n",
    "    x=[]\n",
    "    for j in range(len(l)):\n",
    "        if i<len(l[0]) and l[j][i]!=np.nan:\n",
    "            x.append(l[j][i])\n",
    "        else:\n",
    "            x.append(np.nan)\n",
    "    test_df[f\"attr_{i+1}\"]=x\n",
    "print(test_df.isna().sum())\n",
    "test_df.to_csv(f\"preds/{category}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhcp4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
